{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial imports\n",
    "import pandas as pd \n",
    "import pandas_datareader.data as web\n",
    "from pandas import Series, DataFrame\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/new_osemn.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing real time stock data via pandas_datareader.data as web, numerous features, the frequency of this data is daily by default, the date is automatically a pandas datetime obj and is already placed on the x axis so there's no need to perform a pivot method.\n",
    "[pandas-datareader](https://pandas-datareader.readthedocs.io/en/latest/remote_data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data via web with this implementation there's no need to change date to datetime obj or perform a pivot  \n",
    "# slicing(subsetting) just change the start and end parameters below:\n",
    "start = dt.datetime(2017, 1, 1)\n",
    "end = dt.datetime(2019, 1, 1)\n",
    "\n",
    "SNP = web.DataReader('^GSPC', 'yahoo', start, end).sort_index(ascending=False) # index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import json\n",
    "\n",
    "tweet = open('data/condensed_2017.json')\n",
    "tweets = open('data/condensed_2018.json')\n",
    "\n",
    "tweet17 = json.load(tweet) # 2017 tweets\n",
    "tweet18 = json.load(tweets) # 2018 tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrub:\n",
    "###### S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy dataframe\n",
    "SNP2 = SNP.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the S&P 500 Index\n",
    "SNP.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only interested in the Closing price of the trading day\n",
    "SNP.drop(['High', 'Low', 'Open', 'Adj Close', 'Volume'], axis= 1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tail is the most current data\n",
    "# this data is daily frequency\n",
    "print(SNP.head())\n",
    "print(SNP.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNP.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial shape based on the start and end parameters of the imports\n",
    "SNP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annual number of trading days limited (of course)\n",
    "from IPython.display import Image\n",
    "Image(filename='images/trading_day.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNP.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no missing values, daily returns\n",
    "SNP.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line plot\n",
    "SNP.plot(figsize = (16,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot plot\n",
    "# this looks good very similiar to the line plot no outliers just pure data points\n",
    "SNP.plot(figsize=(20,6), style= '.b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas grouper to group values using annual frequency\n",
    "year_groups = SNP['Close'].groupby(pd.Grouper(freq ='A'))\n",
    "\n",
    "# Create a new DataFrame and store yearly values in columns \n",
    "SNP_annual = pd.DataFrame()\n",
    "\n",
    "for yr, group in year_groups:\n",
    "    SNP_annual[yr.year] = group.values\n",
    "    \n",
    "# Plot the yearly groups as subplots\n",
    "SNP_annual.plot(figsize= (13,8), subplots= True, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram\n",
    "SNP.hist(figsize = (10,6), bins= 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# density plot\n",
    "SNP.plot(kind='kde', figsize = (15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good for spotting outliers, not that there are any in this data\n",
    "SNP_annual.boxplot(figsize = (12,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series heat map\n",
    "year_matrix = SNP_annual.T\n",
    "plt.matshow(year_matrix, interpolation=None, aspect='auto', cmap=plt.cm.Spectral_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stationarity\n",
    "The stationarity was performed much later in this process and the numbers were horrendous, upon gathering some domain knowledge on time series data namely predicting stock, this type of data is susceptible to stationarity over any trending or seasonality issues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to check for the stationarity of a given time series using rolling stats and DF test\n",
    "# Collect and package the code from previous labs\n",
    "def stationarity_check(TS):\n",
    "    \n",
    "    # Import adfuller\n",
    "    from statsmodels.tsa.stattools import adfuller\n",
    "    \n",
    "    # Calculate rolling statistics\n",
    "    roll_mean = TS.rolling(window=8, center=False).mean()\n",
    "    roll_std = TS.rolling(window=8, center=False).std()\n",
    "    \n",
    "    # Perform the Dickey Fuller Test\n",
    "    dftest = adfuller(TS['Close'])\n",
    "    \n",
    "    # Plot rolling statistics:\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.plot(TS, color='blue',label='Original')\n",
    "    plt.plot(roll_mean, color='red', label='Rolling Mean')\n",
    "    plt.plot(roll_std, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    # Print Dickey-Fuller test results\n",
    "    print('Results of Dickey-Fuller Test: \\n')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', \n",
    "                                             '#Lags Used', 'Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationarity_check(SNP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a log transform\n",
    "ts_log = np.log(SNP)\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.plot(ts_log, color='blue');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a square root transform\n",
    "ts_sqrt = np.sqrt(SNP)\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.plot(ts_sqrt, color='blue');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtracting the rolling mean\n",
    "roll_mean = np.log(SNP).rolling(window=7).mean()\n",
    "fig = plt.figure(figsize=(11,7))\n",
    "plt.plot(np.log(SNP), color='blue', label='Original')\n",
    "plt.plot(roll_mean, color='red', label='Rolling Mean')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Log Transformed Data')\n",
    "plt.show(block=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract the moving average from the log transformed data\n",
    "data_minus_roll_mean = np.log(SNP) - roll_mean\n",
    "# Print the first 10 rows\n",
    "data_minus_roll_mean.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the missing values\n",
    "data_minus_roll_mean.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11,7))\n",
    "plt.plot(data_minus_roll_mean, color='blue',label='Close - rolling mean')\n",
    "plt.legend(loc='best')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationarity_check(data_minus_roll_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_minus_roll_mean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Presidential Tweets\n",
    "##### 2017 Tweets\n",
    "Here I've gather President Trumps tweet history which encompases the month he took office January 20, 2017 in the form of a couple of json files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tweet17)) # 2605 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json list to pandas Dataframe obj\n",
    "Tweets_17_df = DataFrame(tweet17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns check\n",
    "Tweets_17_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "May end up dropping source as well and just treat every tweet as presidential not \n",
    "just the ones eminating from the iPhone. Will have to clean up the text and use the created_at\n",
    "as a datetime index obj, is_retweet could be used to filter out retweets later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unneeded columns\n",
    "Tweets_17_df.drop(['id_str', 'retweet_count', \n",
    "                   'in_reply_to_user_id_str', 'favorite_count', 'source'], axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove retweets(RT)\n",
    "Tweets_17_df= Tweets_17_df[Tweets_17_df.is_retweet != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping is_retweet column\n",
    "Tweets_17_df.drop(['is_retweet'], axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change col created_at to Date\n",
    "Tweets_17_df.rename(columns={'created_at':'Date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing created_at to datetime index obj\n",
    "# dropping the timestamp\n",
    "Tweets_17_df['Date'] = pd.to_datetime(Tweets_17_df['Date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_17_df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_17_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets are already in decending order\n",
    "Tweets_17_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_17_df.text[34]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2018 Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tweet18)) # 3510 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 tweets to DataFrame obj\n",
    "Tweets_18_df = DataFrame(tweet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unneeded columns\n",
    "Tweets_18_df.drop(['id_str', 'retweet_count', \n",
    "                   'in_reply_to_user_id_str', 'favorite_count', 'source'], axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove retweets(RT)\n",
    "Tweets_18_df= Tweets_18_df[Tweets_18_df.is_retweet != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping is_retweet column\n",
    "Tweets_18_df.drop(['is_retweet'], axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change col created_at to Date\n",
    "Tweets_18_df.rename(columns={'created_at':'Date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing created_at to datetime index obj\n",
    "# dropping the timestamp\n",
    "Tweets_18_df['Date'] = pd.to_datetime(Tweets_18_df['Date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_18_df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_18_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets are already in decending order\n",
    "Tweets_18_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_18_df.text[34]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore:\n",
    "\n",
    "##### Merged Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking Tweets no NaN values and other columns being created with outer merge\n",
    "Tweets = pd.concat([Tweets_17_df, Tweets_18_df], axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tweets text cleanup isle 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have an idea for an interactive graph so I'll perform some text cleanup here\n",
    "def txtClean(text):\n",
    "    \"\"\"cleaning text\"\"\"\n",
    "    text = re.sub('@[A-Za-z0–9]+', '', text) \n",
    "    text = re.sub('#', '', text) \n",
    "    text = re.sub('https?:\\/\\/\\S+', '', text)\n",
    "    text = text.title() # for graphing time permitting\n",
    "    text = text.lstrip() # suppose to be removing leading space in text\n",
    "    \n",
    "    \n",
    "    return text\n",
    "\n",
    "Tweets['text'] = Tweets['text'].apply(txtClean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Twts = Tweets_18_df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets are suppose to be limited to 140 chars but many of these tweets are way over 140 chars\n",
    "probably not a factor in what I'm attempting to achieve in this notebook and actually could ad\n",
    "in sentiment analysis, in the creation of additional features to use in a supervised model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets['length'] = [len(t) for t in Tweets.text] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets[Tweets.length > 140].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"TextBlob is a Python (2 and 3) library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\" [TextBlob](https://textblob.readthedocs.io/en/dev/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentiment analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line doesn't like to be reduced to 80 length for some reason\n",
    "tweet_example = TextBlob('the democrats have been told and fully understand that there can be no daca without the desperately needed wall at the southern border and an end to the horrible chain migration ridiculous lottery system of immigration etc we must protect our country at all cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob seems to have manipulated the text enough to just obtain sentiment scores without additional steps\n",
    "tweet_example.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_example.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how I will determine if a tweet is positive or negative\n",
    "with multiple tweets in a given day I tally the sentiment amoung them together and just\n",
    "take the average, much like a daily presidential sentiment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_example.sentiment.polarity\n",
    "# on a scale of 1(pos) and -1(neg)\n",
    "-0.504166666666667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "polarity - how positive or negative a word is -1 very neg, +1 very pos <br> \n",
    "subjectivity - how opinionated a word is 0 fact, +1 very much an opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob test\n",
    "# values are identical when lowercase and all punctuations removed.\n",
    "TextBlob('the democrats have been told and fully understand that there can be no daca without the desperately needed wall at the southern border and an end to the horrible chain migration ridiculous lottery system of immigration etc we must protect our country at all cost').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob('I hope everyone is having a great Christmas, then tomorrow it’s back to work in order to Make America Great Again (which is happening faster than anyone anticipated)!').sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob('There is right now a full scale manhunt going on in California for an illegal immigrant accused of shooting and killing a police officer during a traffic stop. Time to get tough on Border Security. Build the Wall!').sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Sentiment | Polarity 2017 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis on 2017 dataframe\n",
    "polarity = lambda x: TextBlob(x).sentiment.polarity\n",
    "subjectivity = lambda x: TextBlob(x).sentiment.subjectivity\n",
    "\n",
    "Tweets['polarity'] = Tweets['text'].apply(polarity) \n",
    "Tweets['subjectivity'] = Tweets['text'].apply(subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with multiple tweets in a single date\n",
    "Tweet_analysis = Tweets.groupby('Date')['polarity', 'subjectivity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweet_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweet_analysis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging sentiment data with SNP data\n",
    "analysis_SNP_df = Tweet_analysis.merge(data_minus_roll_mean, how='right', left_index= True, right_index=True)\n",
    "analysis_SNP_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_SNP_df.dropna(axis= 0, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_SNP_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model:\n",
    "##### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot\n",
    "from math import sqrt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_SNP_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling Close feature\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "analysis_SNP_df.Close = scaler.fit_transform(np.array(analysis_SNP_df.Close).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_SNP_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the outcome and predictor variables\n",
    "y = analysis_SNP_df['Close']\n",
    "X = analysis_SNP_df.drop('Close', axis=1) \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no stationarity performed on these metrics\n",
    "X.plot(figsize=(20,6), style= '.b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.plot(figsize = (16,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.hist(figsize= (10,6), bins= 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.20, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForestRegressor\n",
    "\n",
    "Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set. (wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit a RandomForestRegressor\n",
    "# utilizing hyperparameters from exhaustive GridSearchCV\n",
    "rfr = RandomForestRegressor(criterion = 'mae', \n",
    "                            max_depth = 3, \n",
    "                            max_features = 'sqrt', \n",
    "                            n_estimators = 50, \n",
    "                            n_jobs = -1) \n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "rfr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicated which feature is more important (not weighted)\n",
    "def plot_feature_importances(model):\n",
    "    n_features = X_train.shape[1]\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(n_features), X_train.columns.values) \n",
    "    plt.xlabel('Feature importance')\n",
    "    plt.ylabel('Feature')\n",
    "    \n",
    "    \n",
    "plot_feature_importances(rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - y_test)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Average model error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / y_test)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root mean squared error\n",
    "rsme = math.sqrt(mean_squared_error(y_test, predictions))\n",
    "rsme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter RandomForestRegressor tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GridSearchCV\n",
    "# gsc = GridSearchCV(estimator = RandomForestRegressor(),\n",
    "# param_grid = {\n",
    "#     'criterion': ('mse', 'mae'),\n",
    "#     'max_depth': range(3, 7), \n",
    "#     'max_features': ('auto', 'sqrt','log2'), \n",
    "#     'n_estimators': (10 , 50, 100, 1000),\n",
    "#     'n_jobs': (None, -1),\n",
    "#     }, cv = 5, return_train_score= False)\n",
    "\n",
    "# grid_result = gsc.fit(X, y)\n",
    "# best_params = grid_result.best_params_\n",
    "\n",
    "# rfr = RandomForestRegressor(criterion = best_params['criterion'],\n",
    "#                            max_depth = best_params['max_depth'],\n",
    "#                            max_features = best_params['max_features'],\n",
    "#                            n_estimators = best_params['n_estimators'],\n",
    "#                            n_jobs = best_params['n_jobs'], \n",
    "#                             random_state= False, verbose= False)\n",
    "\n",
    "\n",
    "# gsc.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # results from GridSearchCV saved in pandas DataFrame obj\n",
    "# df = pd.DataFrame(gsc.cv_results_)\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filtering dataframe results\n",
    "# df[['param_criterion', 'param_max_depth', 'param_n_estimators', 'params', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # best hyperparameters\n",
    "# gsc.best_estimator_\n",
    "\n",
    "# # RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
    "# #                       max_depth=3, max_features='sqrt', max_leaf_nodes=None,\n",
    "# #                       max_samples=None, min_impurity_decrease=0.0,\n",
    "# #                       min_impurity_split=None, min_samples_leaf=1,\n",
    "# #                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "# #                       n_estimators=50, n_jobs=-1, oob_score=False,\n",
    "# #                       random_state=None, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # best score\n",
    "# gsc.best_score_\n",
    "\n",
    "# -0.05714325184018758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters\n",
    "gsc.best_params_\n",
    "\n",
    "# {'criterion': 'mae',\n",
    "#  'max_depth': 3,\n",
    "#  'max_features': 'sqrt',\n",
    "#  'n_estimators': 50,\n",
    "#  'n_jobs': -1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LinearRegression with Sentiment Analysis results\n",
    "\n",
    "Linear regression is a linear approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). (wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = analysis_SNP_df[['subjectivity', 'polarity']].values\n",
    "tar = analysis_SNP_df['Close'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train1, y_test1 = train_test_split(feat, tar, test_size= 0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x_train, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.coef_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing model returns the coef of the determination R**2 of the prediction\n",
    "# best possible score is 1.0\n",
    "lr_confidence = lr.score(x_test, y_test1)\n",
    "print('lr confidence:', lr_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_df = pd.DataFrame({'Actual': y_test1, 'Predicted': y_pred})\n",
    "linreg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test1, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test1, y_pred))\n",
    "print('Root Mean Squared Error:', math.sqrt(metrics.mean_squared_error(y_test1, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = linreg_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LinearRegression with just Stock features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of SNP dataframe for comparison\n",
    "# raw data no stationarity or scaling\n",
    "SNP2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target is still Close\n",
    "feat2 = SNP2[['High', 'Low', 'Open', 'Volume']].values\n",
    "tar2 = SNP2['Close'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(feat2, tar2, test_size= 0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.coef_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing model returns the coef of the determination R**2 of the prediction\n",
    "# best possible score is 1.0\n",
    "confidence = lr.score(x_test2, y_test2)\n",
    "print('Confidence:', confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_df = pd.DataFrame({'Actual': y_test2, 'Predicted': y_pred})\n",
    "linreg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test2, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test2, y_pred))\n",
    "print('Root Mean Squared Error:', math.sqrt(metrics.mean_squared_error(y_test2, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = linreg_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural Network, long short-term memory (LSTM)\n",
    "A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell.\n",
    "\n",
    "LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series. LSTMs were developed to deal with the vanishing gradient problem that can be encountered when training traditional RNNs. Relative insensitivity to gap length is an advantage of LSTM over RNNs, hidden Markov models and other sequence learning methods in numerous applications. (wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_SNP_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split time series data\n",
    "train_size = int(len(analysis_SNP_df) * 0.8)\n",
    "test_size = len(analysis_SNP_df) - train_size\n",
    "train, test = analysis_SNP_df.iloc[0: train_size], analysis_SNP_df.iloc[train_size: len(analysis_SNP_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data prep\n",
    "# array of values into dataset matrix\n",
    "def create_dataset(X, y, time_steps= 1):\n",
    "    \"\"\"frames a sequence as a supervised learning problem\"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i: (i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 22 # not a lot of data here so this values gonna be small based on frequency\n",
    "# train.Close is y\n",
    "X_train, y_train = create_dataset(train, train.Close, time_steps)\n",
    "X_test, y_test, = create_dataset(test, test.Close, time_steps)\n",
    "# will print samples/batches, time_steps, # of features\n",
    "print(X_train.shape, y_train.shape) # train shape\n",
    "print(X_test.shape, y_test.shape) # test shape\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(10, return_sequences= True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(10, return_sequences= True))\n",
    "model.add(LSTM(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 100, batch_size = 64, verbose= 1, validation_split = 0.1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label= 'train')\n",
    "plt.plot(history.history['val_loss'], label= 'validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE performance metrics\n",
    "math.sqrt(mean_squared_error(y_train, train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data RMSE\n",
    "math.sqrt(mean_squared_error(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 20\n",
    "trainPredictPlot = np.empty_like(analysis_SNP_df.Close)\n",
    "trainPredictPlot[:, :] = np.nan \n",
    "trainPredictPlot[look_back: len(train_pred) + look_back, :] = train_predict\n",
    "\n",
    "testPredictPlot = np.empty_like(analysis_SNP_df.Close)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(train_predict) + (look_back * 2) + 1: len(analysis_SNP_df) - 1, :] = test_predict\n",
    "\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tweet Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ' '.join([tweet for tweet in Twts['text']])\n",
    "wordCloud = WordCloud(width=800, height=600, random_state= 21, max_font_size= 120).generate(words)\n",
    "\n",
    "plt.imshow(wordCloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204.799px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
